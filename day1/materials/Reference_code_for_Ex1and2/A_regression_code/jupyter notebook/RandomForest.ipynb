{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b593ba-4aad-49da-8721-35a6601099bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林 Hyperopt\n",
    "# 定义超参数搜索空间\n",
    "\n",
    "parameter_space_rf = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 30, 80, 1),  # 使用 quniform 生成整数范围\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 1), # max_depth_rf),  # 树的最大深度\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),  # 分裂所需最小样本数（整数）\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1),  # 叶节点最小样本数（整数）\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', 2, 3, 4, 5]) # 控制每棵树在分裂时考虑的最大特征数量\n",
    "}\n",
    "\n",
    "# 定义目标函数\n",
    "def rf_objective(params):\n",
    "    # 处理 max_depth 中的 None 值\n",
    "    # params['max_depth'] = None if params['max_depth'] == 0 else params['max_depth']\n",
    "    # 打印当前参数\n",
    "    print(\"Parameters: \", params)\n",
    "    # 创建随机森林回归模型\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=int(params['n_estimators']), \n",
    "        max_depth=int(params['max_depth']),\n",
    "        min_samples_split=int(params['min_samples_split']),\n",
    "        min_samples_leaf=int(params['min_samples_leaf']),\n",
    "        max_features=params['max_features'],\n",
    "        random_state=random_seed\n",
    "    )\n",
    "\n",
    "    # 使用交叉验证评估模型性能\n",
    "    mse_scores = cross_val_score(model, X_train_CoRE_scaled, y_train_CoRE, cv=10, scoring='neg_mean_squared_error')\n",
    "    mse = -np.mean(mse_scores)  # 转换为正数的 MSE\n",
    "\n",
    "    # 返回 MSE，Hyperopt 会最小化该目标值\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "# 运行超参数优化\n",
    "trials_rf = Trials()\n",
    "best_params_rf = fmin(    \n",
    "    fn=rf_objective,                # 优化的目标函数    \n",
    "    space=parameter_space_rf,       # 搜索空间    \n",
    "    algo=tpe.suggest,               # 贝叶斯优化算法    \n",
    "    max_evals=200,                  # 最大评估次数\n",
    "    trials=trials_rf,\n",
    "    rstate=np.random.default_rng(random_seed)\n",
    ")\n",
    "print(\"Best parameters : \", best_params_rf)\n",
    "\n",
    "# 处理 hp.choice 返回的索引值\n",
    "best_params_rf['n_estimators'] = int(best_params_rf['n_estimators'])\n",
    "best_params_rf['max_depth'] = int(best_params_rf['max_depth'])\n",
    "best_params_rf['max_features'] = ['sqrt', 'log2', 2, 3, 4, 5][best_params_rf['max_features']]\n",
    "\n",
    "# 使用最佳参数创建随机森林回归模型\n",
    "best_model_rf = RandomForestRegressor(\n",
    "    n_estimators=best_params_rf['n_estimators'],\n",
    "    max_depth=best_params_rf['max_depth'],\n",
    "    min_samples_split=int(best_params_rf['min_samples_split']),\n",
    "    min_samples_leaf=int(best_params_rf['min_samples_leaf']),\n",
    "    max_features=best_params_rf['max_features'],\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# 在训练集上训练模型\n",
    "best_model_rf.fit(X_train_CoRE_scaled, y_train_CoRE)\n",
    "\n",
    "# 保存最优模型\n",
    "model_rf = './RF_2.pkl'\n",
    "joblib.dump(best_model_rf, model_rf)\n",
    "print(f\"Model saved to {model_rf}\")\n",
    "# 查看加载模型的参数\n",
    "#loaded_model = joblib.load(model_rf)\n",
    "#print(\"Loaded model parameters: \", loaded_model.get_params())\n",
    "# 如果需要加载模型并进行预测\n",
    "# loaded_model = joblib.load(model_filename)\n",
    "# y_pred = loaded_model.predict(X_test_CoRE_scaled)\n",
    "# print(\"Predictions: \", y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deep]",
   "language": "python",
   "name": "conda-env-.conda-deep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
